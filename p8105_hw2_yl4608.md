p8105\_hw2\_yl4608.Rmd
================
Yutian Luo
9/28/2020

# Problem 1

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read\_excel

``` r
trash_data = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%       # horizontally define range
  janitor::clean_names()%>%             # clean the names to lower cases
  drop_na(dumpster)%>%
  
  mutate(
    #round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean precipitation data for 2017 and 2018. For each, omit rows
without precipitation data and add a variable year.

``` r
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1                       # skip the title column
    )%>%
  janitor::clean_names()%>%
  drop_na(month)%>%                # drop rows without data
  mutate(year = 2017)%>%              # add variable year
  relocate(year)                  # locate year col in front of month col

precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1                       # skip the title column
    )%>%
  janitor::clean_names()%>%
  drop_na(month)%>%                # drop rows without data
  mutate(year = 2018)%>%              # add variable year
  relocate(year)                  # locate year col in front of month col
```

Next, combine precipitation datasets and convert month to a character
variable (the variable month.name is built into R and should be useful).

``` r
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2017, precip_2018)    # combine: add 2018 at the end of 2017
  
left_join(precip_df, month_df, by = "month")   # join all cols in month_df with precip_df, key is month var
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2017     1  2.34 January   
    ##  2  2017     2  1.46 February  
    ##  3  2017     3  3.57 March     
    ##  4  2017     4  3.99 April     
    ##  5  2017     5  5.64 May       
    ##  6  2017     6  1.4  June      
    ##  7  2017     7  7.09 July      
    ##  8  2017     8  4.44 August    
    ##  9  2017     9  1.95 September 
    ## 10  2017    10  0    October   
    ## # … with 14 more rows

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in both resulting datasets,
and give examples of key variables. For available data, what was the
total precipitation in 2018? What was the median number of sports balls
in a dumpster in 2017?

    This dataset has cols of trash data stored in dumpster variable. There total of 344 in the dataset.

# Problem 2

Read and clean the data;

retain line, station, name, station latitude / longitude, routes served,
entry, vending, entrance type, and ADA compliance.

Convert the entry variable from character (YES vs NO) to a logical
variable (the ifelse or recode function may be useful).

``` r
nyc_data = 
    read_csv(
    file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")%>%
  janitor::clean_names()%>%
  
  select(
    line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada)%>%
  
  mutate(
    entry = recode(entry, `YES`=TRUE, `NO` = FALSE),    # recode entry variable
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
    )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

Q: Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?

A: This dataset contains transit variables of NYC metro stations, stored
line, station\_name, station\_latitude, station\_longitude, route1,
route2, route3, route4, route5, route6, route7, route8, route9, route10,
route11, entry, vending, entrance\_type, ada variables. I have cleaned
the names of the variables to lower cases, select relevant variables for
analysis, and also change the expression of entry variable to logical
type. This dataset has a dimension of 1868 \* 19. The data is untidy,
since some numeric values are expressed in the variables, such as route
number.

## Answer Questions

Answer the following questions using these data:

Q: How many distinct stations are there? Note that stations are
identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1;
125st 4/5); the distinct function may be useful here.

``` r
distinct_data1 = distinct(nyc_data, line, station_name, .keep_all = TRUE) 
nrow(distinct_data1)
```

    ## [1] 465

A:

    There are 465 distinct stations.

Q: How many stations are ADA compliant?

A:

    There are 84 ADA compliant stations.

Q: What proportion of station entrances / exits without vending allow
entrance?

``` r
# stations no vending 
num_novend = nrow(filter(nyc_data, vending == "NO")) 
# stationa no vending && allow entrance
num_novend_enter = nrow(filter(nyc_data, vending == "NO", entry == TRUE ))
# calculate porportion
prop = num_novend_enter/num_novend
```

A:

``` 
There are 37.704918 % of such stations.  
```

## Reformat data

Reformat data so that route number and route name are distinct
variables.

``` r
#reformat data
nyc_tidy_data = 
  select(nyc_data, route1:route11, station_name, line, ada) %>% 
    pivot_longer(
    route1 : route11,
    names_to = "route_number",
    values_to = "route_name") %>% 
  relocate(route_number, route_name)

view(nyc_tidy_data)
```

Q: How many distinct stations serve the A train?

``` r
nyc_tidy_data_df1 = 
  distinct(nyc_tidy_data, line, station_name, .keep_all = TRUE) %>% 
  filter(route_name == "A")
```

A: There are 60 distinct stations serve the A train.

Q: Of the stations that serve the A train, how many are ADA compliant?

``` r
nyc_tidy_data_df2 =
  distinct(nyc_tidy_data, line, station_name, .keep_all = TRUE) %>% 
  filter(route_name == "A", ada == TRUE) 
```

A: There are 17 A train stations that are ada compliant.

# problem 3

First, clean the data in pols-month.csv.

Use separate() to break up the variable mon into integer variables year,
month, and day;

replace month number with month name;

create a president variable taking values gop and dem, and remove
prez\_dem and prez\_gop; and remove the day variable.

``` r
pols_data =
  read_csv(
    file = "./data/fivethirtyeight_datasets/pols-month.csv"
  )%>%
  janitor::clean_names()%>%
  #convert mon into character first
  mutate(                      
    mon = as.character(mon)
  ) %>%
  # use separte func to seperate and convert date into 3 vars
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
#create month df
month_df2 =
  tibble(
    month = 1:12,
    month_name = month.name
  )

#replace month number with month name
pols_data = 
  left_join(pols_data, month_df2, by = "month") %>% 
  select(-month) %>% 
  relocate(year, month_name, day, prez_gop, prez_dem) %>% 

#create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
  pivot_longer(
    prez_gop:prez_dem,
    names_to = "president"
  ) %>% 
  select(-value) %>% 
  select(-day) %>% 
  arrange(year, month_name) %>% 
  relocate(year, month_name, president) %>% 
  mutate( month_name = month.abb[as.factor(month_name)],
          year = as.integer(year)
        )

view(pols_data)
```

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_data = 
  read.csv(
    file = "./data/fivethirtyeight_datasets/snp.csv"
    ) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month","day","year"), sep = "/", convert = TRUE) %>%
  
#organize date variables
  mutate(
    month = as.integer(month),
    day = as.integer(day),
    year = as.integer(year)
  ) %>%
  select(-day) %>% 
  relocate(year, month) %>% 
  arrange(year, month) 

# replace month number with month names
snp_data =
  left_join(snp_data, month_df2, by = "month") %>% 
  select(-month) %>% 
  relocate(year, month_name) %>% 
  mutate( month_name = month.abb[as.factor(month_name)],
          year = as.integer(year)
        )

  
view(snp_data)
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemp_data = 
  read.csv(
    file = "./data/fivethirtyeight_datasets/unemployment.csv"
    ) %>% 
  janitor::clean_names() %>% 
  
# pivot to long format
  pivot_longer(
    jan:dec,
    names_to = "month_name",
    values_to = "unemployment"
  ) %>% 

# ensure key variables have same name and same value
  arrange(year, month_name) %>% 
  mutate( month_name = month.abb[as.factor(month_name)],
          year = as.integer(year)
        )


view(unemp_data)
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
# merging snp into pols
merge_pols_snp = 
  left_join(pols_data, snp_data, by = c("year","month_name"))

view(merge_pols_snp)

# merging unemployment into the result.
merge_unemp =
  left_join(merge_pols_snp, unemp_data, by = c("year","month_name"))

view(merge_unemp)
```

Q; Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset (e.g. give
the dimension, range of years, and names of key variables).

A:

The pols\_data has variables that describes the election sitation of
each year, it contains variables such as year, month\_name, president,
gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem. It has 1644,
9 dimension in it.

The snp\_data has variables that records the stock market in each months
of the years in between 1950, 2015 in history. It has year, month\_name,
close as variables.

The unemp\_data notes down the unemployment rates in each year and
month. It has in total 816, 3 as dimension. The time duration for this
dataset is between 1948, 2015. It has variables as year, month\_name,
unemployment.

The final dataset has a dimension of 1644, 11, the range of years in
total is 1947, 2015, and the variables are year, month\_name, president,
gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem, close,
unemployment.
